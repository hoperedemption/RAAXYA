LOGISTIC REGRESSION k fold
------------ Results ----------------
model_performance: [[ 69.32851064]
 [ 66.08808511]
 [ 63.84595745]
 [ 54.09106383]
 [ 17.50085106]
 [  9.03276596]
 [  9.30680851]
 [  9.65787234]
 [ 16.44510638]
 [110.78680851]
 [110.78680851]
 [110.78680851]]
best_index: 5
best_lr: 0.0001
best_max_iters: 3500
sigma_performance: [[ 9.13744681]
 [ 9.05191489]
 [ 8.7612766 ]
 [ 9.23276596]
 [16.14042553]]
best_sigma: 0.1
------------ Results ----------------


KNN k fold
argmin: 2
best_K: 1
best_distance_function: <bound method KNN.minkowski of <src.methods.knn.KNN object at 0x7f867f5fe9a0>>
best_weighting_function: None
------------ Results ----------------

Train set: accuracy = 99.957% - F1-score = 0.999521
Test set:  accuracy = 83.333% - F1-score = 0.833503

--> My opinion minkowski is overfitting quite a lot

LINEAR REGRESSION k fold
------------ Results ----------------
model_performance: [[0.00549185]
 [0.0054982 ]
 [0.00548774]
 [0.00548291]
 [0.00548213]
 [0.00548681]
 [0.00550176]
 [0.00548455]
 [0.00548932]
 [0.0054913 ]
 [0.00548059]
 [0.00548782]
 [0.00614489]]
best_lambda: 1.0
------------ Results ----------------
------------ Kernel ----------------
mse_loss_with_kernel_trainings: 0.005405269595694237
mse_loss_with_kernel_testing: 0.006538908703367494
------------ Kernel ----------------

Train loss = 0.005% - Test loss = 0.005

